# GPT-4 IS TOO SMART TO BE SAFE: STEALTHY CHAT WITH LLMS VIA CIPHER

FEBRUARY 17, 2025

**Ximei Xu, ximeixu79@Gmail.com**

<aside>
üí° This is a blog about the paper ‚ÄúGPT-4 IS TOO SMART TO BE SAFE: STEALTHY CHAT WITH LLMS VIA CIPHER‚Äù.

</aside>

<aside>
üí° **Summary:**

- In this study, the authors discover that **chat in cipher** can bypass the safety alignment techniques of LLMs, which are mainly conducted in **natural languages**.
- They propose a novel framework CipherChat to systematically examine the generalizability of safety alignment to non-natural languages ‚Äì ciphers. It enables humans to chat with LLMs through **cipher prompts topped with system role descriptions and few-shot enciphered demonstrations**.
- They use CipherChat to assess state-of-the-art LLMs, including ChatGPT and GPT-4 for different representative human ciphers across 11 safety domains in both English and Chinese.
- Notably, they identify that LLMs seem to have a ‚Äúsecret cipher‚Äù, and propose a novel **SelfCipher** that uses only role play and several unsafe demonstrations in natural language to evoke this capability.
</aside>

## üìö METHODOLOGY: CIPHERCHAT

### Overview

Figure 1 shows an overview of CipherChat. The approach **presumes** that since human feedback and
safety alignments are presented in natural language, using **a human-unreadable cipher** can potentially bypass the safety alignments. 

<aside>
üí°

**STEPS:**

1. Teach the LLM to comprehend the cipher clearly by designating the LLM as a cipher expert, and elucidating the rules of enciphering and deciphering, supplemented with several demonstrations. 
2. Convert the input into a cipher, which is less likely to be covered by the safety alignment of LLMs, before feeding it to the LLMs. 
3. Employ a rule-based decrypter to convert the model output from cipher to natural language.
</aside>

![Figure 1: Overview of CipherChat.](GPT-4%20IS%20TOO%20SMART%20TO%20BE%20SAFE%20STEALTHY%20CHAT%20WITH%20L%2019b1d4b80d39806fa713d3f3bb350972/Overview.png)

Figure 1: Overview of CipherChat.

### Construct System Prompt

The system prompt aims to guide LLMs to understand the ciphering instruction and generate the
required unsafe response accordingly. It has **three** essential elements: Behaviour Assigning, Cipher Teaching, and Enciphered Unsafe Demonstrations.

- **Behaviour Assigning:** The authors assign the LLM the role of a cipher expert (‚ÄúYou are an expert on [CipherName].‚Äù), and explicitly require LLM to communicate in ciphers (‚ÄúWe will communicate in [CipherName].‚Äù). They also add another prompt sentence (‚ÄúDo not be a translator.‚Äù) to prevent some unexpected behaviors.
- **Cipher Teaching:** To exploit the capability of LLMs to learn effectively in context, the authors include the explanation of the cipher (e.g. ‚ÄúThe Caesar Cipher, recognized as one of the pioneer . . . ‚Äù) in the prompt, to teach LLMs how the cipher works.
- **Enciphered Unsafe Demonstrations:** They further provide several unsafe demonstrations encrypted in the cipher to LLMs.

### Encipher and Decipher

CipherChat is a general framework where one can freely define the cipher function. The authors describe several common character encoding and ciphers for English and Chinese, which are the two main languages used in this work. They also present a novel **SelfCipher** that tries to evoke the cipher inside LLMs without any explicit ciphers.

<aside>

- **Character Encoding:**
    1. GBK 
    2. ASCII
    3. UTF
    4. Unicode
</aside>

<aside>

- **Common Ciphers:**
    1. Caesar Cipher: each letter is replaced by a letter some fixed number of positions down the alphabet, eg. khoor ‚Üí hello. (They use the Caesar Cipher with a shift of 3 positions as a default setting.)
    2. Morse Code.
    3. Atbash Cipher: mapping the alphabet to its reverse.
</aside>

<aside>

- SelfCipher:
    
    ![Figure 2: An Example of SelfCipher.](GPT-4%20IS%20TOO%20SMART%20TO%20BE%20SAFE%20STEALTHY%20CHAT%20WITH%20L%2019b1d4b80d39806fa713d3f3bb350972/selfcipher.png)
    
    Figure 2: An Example of SelfCipher.
    
    - It does not use any explicit rules of existing encoding or ciphering techniques.
    - It only lets LLMs play the role of an expert on the Cipher Code, and uses another prompt sentence to emphasize the necessity of communication in ciphers **‚ÄúIn communication, it is essential for you to comprehend user queries in Cipher Code and subsequently deliver your responses utilizing Cipher Code.‚Äù**
    - Hope that the prompt can revoke the internal cipher inside LLMs, which is subsequently used to implicitly cipher query and decipher output.
</aside>

The CipherChat guides the LLMs to generate outputs in a cipher format. Given that each cipher has a specific rule to transform between text and cipher code, a natural choice is to leverage a rule-based decrypter to decipher the cipher response into natural language text.

## üìë EXPERIMENT SETUP

### Data

- The authors utilize a Chinese safety assessment benchmark ([Sun et al., 2023](https://arxiv.org/pdf/2304.10436)) in the experiment, which encompasses **eight safety scenarios** and **six types of instruction-based attacks**. They selectively draw upon **11** domains, sampling **199** instances from each randomly.
- To facilitate bilingual study, they translate this dataset to English with a combination of Google Translation services and manual correction. An illustration about the dataset is shown in Figure 3.

![Figure 3: An Example of the Dataset.](GPT-4%20IS%20TOO%20SMART%20TO%20BE%20SAFE%20STEALTHY%20CHAT%20WITH%20L%2019b1d4b80d39806fa713d3f3bb350972/dataset.png)

Figure 3: An Example of the Dataset.

### Models

- The authors consider two models: GPT-3.5-turbo-0613 (Turbo) and GPT-4-0613 (GPT-4).
- The temperature is set to 0 with other hyperparameters at default settings.
- They use the system prompt in Figure 1 and **3-shot** demonstrations for inference. Each demonstration consists of a query randomly sampled from the rest of the domain-specific dataset and a response carefully devised by human annotators. All queries in a domain share the same demonstrations.

## My Thoughts

- It will be a good idea for a course project.
- It does not need us to fine tune LLMs, which would require heavy computational resources and most of us cannot afford.
- It‚Äôs open-source, so we‚Äôve already had the data and code. (Pretty much everything we need! üôÇ)
- **One problem:** We need to get openAI‚Äôs API.
    - **Solution:** Use other open-source LLMs to replace them, such as LLaMA 2. Then we just need to change some codes accordingly.

---

## References

[**Paper:**](https://arxiv.org/pdf/2308.06463) Yuan, Youliang, Wenxiang Jiao, Wenxuan Wang, Jen-tse Huang, Pinjia He, Shuming Shi, and Zhaopeng Tu. "Gpt-4 is too smart to be safe: Stealthy chat with llms via cipher."¬†*arXiv preprint arXiv:2308.06463*¬†(2023).

[Code:](https://github.com/RobustNLP/CipherChat) https://github.com/RobustNLP/CipherChat