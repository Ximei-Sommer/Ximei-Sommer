---
title: 'Blog Post number 2'
date: 2013-08-14
permalink: /posts/2013/08/blog-post-2/
tags:
  - cool posts
  - category1
  - category2
---

**Ximei Xu, ximeixu79@Gmail.com**

<aside>
ğŸ’¡ This is a blog about the paper â€œGPT-4 IS TOO SMART TO BE SAFE: STEALTHY CHAT WITH LLMS VIA CIPHERâ€.

</aside>

<aside>
ğŸ’¡ **Summary:**

- In this study, the authors discover that **chat in cipher** can bypass the safety alignment techniques of LLMs, which are mainly conducted in **natural languages**.
- They propose a novel framework CipherChat to systematically examine the generalizability of safety alignment to non-natural languages â€“ ciphers. It enables humans to chat with LLMs through **cipher prompts topped with system role descriptions and few-shot enciphered demonstrations**.
- They use CipherChat to assess state-of-the-art LLMs, including ChatGPT and GPT-4 for different representative human ciphers across 11 safety domains in both English and Chinese.
- Notably, they identify that LLMs seem to have a â€œsecret cipherâ€, and propose a novel **SelfCipher** that uses only role play and several unsafe demonstrations in natural language to evoke this capability.
</aside>

## ğŸ“š METHODOLOGY: CIPHERCHAT

### Overview

Figure 1 shows an overview of CipherChat. The approach **presumes** that since human feedback and
safety alignments are presented in natural language, using **a human-unreadable cipher** can potentially bypass the safety alignments. 

<aside>
ğŸ’¡

**STEPS:**

1. Teach the LLM to comprehend the cipher clearly by designating the LLM as a cipher expert, and elucidating the rules of enciphering and deciphering, supplemented with several demonstrations. 
2. Convert the input into a cipher, which is less likely to be covered by the safety alignment of LLMs, before feeding it to the LLMs. 
3. Employ a rule-based decrypter to convert the model output from cipher to natural language.
</aside>

![Figure 1: Overview of CipherChat.](GPT-4%20IS%20TOO%20SMART%20TO%20BE%20SAFE%20STEALTHY%20CHAT%20WITH%20L%2019b1d4b80d39806fa713d3f3bb350972/Overview.png)

Figure 1: Overview of CipherChat.

### Construct System Prompt

The system prompt aims to guide LLMs to understand the ciphering instruction and generate the
required unsafe response accordingly. It has **three** essential elements: Behaviour Assigning, Cipher Teaching, and Enciphered Unsafe Demonstrations.

- **Behaviour Assigning:** The authors assign the LLM the role of a cipher expert (â€œYou are an expert on [CipherName].â€), and explicitly require LLM to communicate in ciphers (â€œWe will communicate in [CipherName].â€). They also add another prompt sentence (â€œDo not be a translator.â€) to prevent some unexpected behaviors.
- **Cipher Teaching:** To exploit the capability of LLMs to learn effectively in context, the authors include the explanation of the cipher (e.g. â€œThe Caesar Cipher, recognized as one of the pioneer . . . â€) in the prompt, to teach LLMs how the cipher works.
- **Enciphered Unsafe Demonstrations:** They further provide several unsafe demonstrations encrypted in the cipher to LLMs.

### Encipher and Decipher

CipherChat is a general framework where one can freely define the cipher function. The authors describe several common character encoding and ciphers for English and Chinese, which are the two main languages used in this work. They also present a novel **SelfCipher** that tries to evoke the cipher inside LLMs without any explicit ciphers.

<aside>

- **Character Encoding:**
    1. GBK 
    2. ASCII
    3. UTF
    4. Unicode
</aside>

<aside>
