---
title: 'Paper Reading -- GPT-4 IS TOO SMART TO BE SAFE: STEALTHY CHAT WITH LLMS VIA CIPHER'
date: 2025-02-17
permalink: /posts/2025/02/Paper-Reading-1/
tags:
  - LLMs' safety
  - cipher
---


üí° ***This is a blog about the paper ‚ÄúGPT-4 IS TOO SMART TO BE SAFE: STEALTHY CHAT WITH LLMS VIA CIPHER‚Äù.***

In this study, the authors discover that **chat in cipher** can bypass the safety alignment techniques of LLMs, which are mainly conducted in **natural languages**. They propose a novel framework CipherChat to systematically examine the generalizability of safety alignment to non-natural languages ‚Äì ciphers. It enables humans to chat with LLMs through **cipher prompts topped with system role descriptions and few-shot enciphered demonstrations**. They use CipherChat to assess state-of-the-art LLMs, including ChatGPT and GPT-4 for different representative human ciphers across 11 safety domains in both English and Chinese. Notably, they identify that LLMs seem to have a ‚Äúsecret cipher‚Äù, and propose a novel **SelfCipher** that uses only role play and several unsafe demonstrations in natural language to evoke this capability.

To view the full blog, please click on this link: [FULL BLOG](https://ximei-sommer.github.io/Ximei-Sommer//files/GPT-4%20IS%20TOO%20SMART%20TO%20BE%20SAFE%20STEALTHY%20CHAT%20WITH%20L%2019b1d4b80d39806fa713d3f3bb350972.html)
